{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9iOMRSZzeJaO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "inf=float(\"inf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training will be faster if you have a GPU. You could use Google Colab although they are getting more restrictive to provide GPU instances for non-paying users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iZ9v9P1ueJaP"
      },
      "outputs": [],
      "source": [
        "#device = torch.device(\"cuda:0\")\n",
        "device = torch.device(\"cpu:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PZoPr82ReJaP"
      },
      "outputs": [],
      "source": [
        "## loading the data: point clouds and diagrams\n",
        "dirPath = \"./data/\"\n",
        "diagrams = np.load(dirPath + \"/diagrams.npy\", allow_pickle=True)\n",
        "y = np.load(dirPath + \"/pointclouds_y.npy\", allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "217"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(y), set(y)\n",
        "len(diagrams[0])\n",
        "diagrams[0]\n",
        "len(diagrams[0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following part is exactly the same as in the previous notebook, it's just to prepare the input to the neural network: it will be by default the stable ranks for H1 with no contour or anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4idk44iweJaP"
      },
      "outputs": [],
      "source": [
        "## Parameters\n",
        "H = \"H1\"\n",
        "w_p = inf\n",
        "\n",
        "density = False\n",
        "mu = 0.15\n",
        "sigma = 0.05\n",
        "\n",
        "limit = 1000\n",
        "\n",
        "classes_chosen = [0, 1, 2, 3, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d7li0nHieJaP"
      },
      "outputs": [],
      "source": [
        "#correspondence by index of: \n",
        "barLengths = [] # bars of diagram, sorted by length, with a possible density transformation \n",
        "ys = [] # class of the diagram\n",
        "the_dgs = [] # actual diagram\n",
        "\n",
        "random_inds = np.random.choice(1000, size=limit, replace=False)\n",
        "#random_inds = list(range(1000))\n",
        "\n",
        "for c in classes_chosen:\n",
        "\n",
        "  #for dg in diagrams[y==c][:limit,:]:\n",
        "  for dg in diagrams[y==c][random_inds]:\n",
        "    if H==\"H1\":\n",
        "      if density:\n",
        "        barLengths.append(np.sort(norm.cdf(dg[1][:,1], loc=mu, scale=sigma) - norm.cdf(dg[1][:,0], loc=mu, scale=sigma)))\n",
        "      else:\n",
        "        barLengths.append(np.sort(dg[1][:,1] - dg[1][:,0]))\n",
        "\n",
        "      the_dgs.append(dg[1])\n",
        "\n",
        "    elif H==\"H0\":\n",
        "      if density:\n",
        "        barLengths.append(np.sort(norm.cdf(dg[0][:-1,1], loc=mu, scale=sigma) - norm.cdf(dg[0][:-1,0], loc=mu, scale=sigma)))\n",
        "      else:\n",
        "        barLengths.append(np.sort(dg[0][:-1,1] - dg[0][:-1,0]))\n",
        "\n",
        "      the_dgs.append(dg[0])\n",
        "\n",
        "    ys.append(c)\n",
        "\n",
        "sizes = [len(i) for i in barLengths] # extract the number of bars for each diagram\n",
        "\n",
        "if w_p != inf:\n",
        "\n",
        "  barLengths2 = []\n",
        "\n",
        "  for b in barLengths:\n",
        "    barLengths2.append(np.cumsum(b ** w_p) ** (1 / w_p))\n",
        "\n",
        "  barLengths = barLengths2 # Lp norms\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m7QXMTYSeJaQ"
      },
      "outputs": [],
      "source": [
        "indices = list(range(len(barLengths)))\n",
        "\n",
        "indTrain, indTest, yTrain, yTest = train_test_split(indices, ys, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtkpXp_VeJaQ",
        "outputId": "11317de7-d57a-43b7-f818-279b535cb5ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(barLengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rKhCghHYeJaQ"
      },
      "outputs": [],
      "source": [
        "maxSize = np.max([i.shape[0] for i in barLengths]) # the max number of bars among diagrams\n",
        "\n",
        "vecs = np.zeros((len(barLengths), maxSize)) # matrix num_diags x max_possible_len_of_each_dg\n",
        "\n",
        "for i in range(len(barLengths)):\n",
        "  vecs[i, :barLengths[i].shape[0]] = np.sort(barLengths[i])[::-1] # at each row the  diagram by increasing values (where available)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lTiU5CRCjr-G"
      },
      "outputs": [],
      "source": [
        "matrixSTens = torch.from_numpy(vecs) # cast to tensor all vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- _matrixSTens_ will contain the vectors we use as input to the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5000, 288])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrixSTens.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh8-RquteJaQ"
      },
      "source": [
        "# Neural network boiler plate\n",
        "\n",
        "The classes and functions below are just standard PyTorch Dataset and code to report accuracy on test set (but please check in case you see some problem with it :-) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "REOTsGpqeJaR"
      },
      "outputs": [],
      "source": [
        "class TheDataset(Dataset):\n",
        "  def __init__(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.length = len(x)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.x[idx],self.y[idx]\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "def test(dataloader, model, loss_fn, p):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    preds = []\n",
        "    ground_truth = []\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "          pred = model(X.float().to(device), p)\n",
        "          #return pred, y\n",
        "          test_loss += loss_fn(pred, y).item()\n",
        "          correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "          preds.append(pred.argmax(1))\n",
        "          ground_truth.append(y)\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    #print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    return test_loss, correct, preds, ground_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SsNE7kYfeJaR"
      },
      "outputs": [],
      "source": [
        "trainset = TheDataset(matrixSTens[indTrain,:], torch.tensor(yTrain).to(device))\n",
        "trainloader = DataLoader(trainset,batch_size=4000,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ozauyva2eJaR"
      },
      "outputs": [],
      "source": [
        "testset = TheDataset(matrixSTens[indTest,:], torch.tensor(yTest).to(device))\n",
        "testloader = DataLoader(testset,batch_size=1000,shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# L inf layer\n",
        "\n",
        "Now we enter the meat of the project.\n",
        "\n",
        "I define the layer and its forward function which just uses PyTorch cdist to compute all distances between the batch and the parameter vectors. One can also pass in _p_ because in the paper they suggest that although in the end we want $p=\\infty$ it can be good to train with schedules increasing in value, so this is something we can try.\n",
        "\n",
        "The initialization of the parameters has a huge importance and this is something we should think about and experiment with, this you can see in the constructor. Here I initialize the parameters of the first layer to have the same scale (mean and standard deviation) as the data (I think this is ok to do, let me know what you think. We should only do it based on the training set however not on the whole data as I do it now, but I don't think it will have a big impact). For the next layers I just initialize it based on a bit of trial and error...\n",
        "\n",
        "\n",
        "Also note that there is in fact some code that comes with the paper https://arxiv.org/pdf/2102.05363 but I chose to build it from scratch to get a better understanding. We could however compare to their code later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-7GaAMbkeJaS"
      },
      "outputs": [],
      "source": [
        "class linfLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, in_blocks, out_blocks, layer_num):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer_num = layer_num\n",
        "\n",
        "        if layer_num==1:\n",
        "          params = matrixSTens.mean(axis=0) + torch.randn((out_blocks, in_blocks)) * matrixSTens.std(axis=0) # normalization\n",
        "          self.params = torch.nn.Parameter(data=params.float().to(device))\n",
        "\n",
        "        else:\n",
        "          params = torch.randn((out_blocks, in_blocks)) * 0.05\n",
        "\n",
        "          self.params = torch.nn.Parameter(data=params.float().to(device))\n",
        "\n",
        "    def forward(self, x, p):\n",
        "\n",
        "        res = torch.cdist(x, self.params, p=p) #torch.cdist but with custom params\n",
        "\n",
        "        return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We combine several (3 in this case) layers in a model below.\n",
        "\n",
        "Here the important step is that we in the forward method center the data (kind of batch normalization but only the centering part, not dividing by standard deviation because that would break the Lipschitzness)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QGCXVvYKeJaS"
      },
      "outputs": [],
      "source": [
        "class linfModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(linfModel,self).__init__()\n",
        "\n",
        "    self.layer1 = linfLayer(in_blocks=288, out_blocks=300, layer_num=1)\n",
        "    self.layer2 = linfLayer(in_blocks=300, out_blocks=100, layer_num=2)\n",
        "    self.layer3 = linfLayer(in_blocks=100, out_blocks=5, layer_num=3)\n",
        "\n",
        "  def forward(self, x, p):\n",
        "    x = self.layer1(x, p)\n",
        "    x = x - x.mean(axis=0)\n",
        "    x = self.layer2(x, p)\n",
        "    x = x - x.mean(axis=0)\n",
        "    x = self.layer3(x, p)\n",
        "    \n",
        "    return x\n",
        "\n",
        "  def get_embs(self, x, p):\n",
        "    x = self.layer1(x, p)\n",
        "    x = x - x.mean(axis=0)\n",
        "    #x = self.layer2(x, p)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Gs-8pHlieJaS"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "\n",
        "# Model , Optimizer, Loss\n",
        "model = linfModel().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.05, eps=1e-06)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ-gM3WkeJaS",
        "outputId": "9d066ad4-aeba-48a1-9384-63406b0b2bd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([300, 288])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(model.parameters())[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The schedule is if we want to train first with lower values of $p$ (see the paper). If you just want $p=\\infty$ from all epochs you can do as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "frKGd-vHeJaS"
      },
      "outputs": [],
      "source": [
        "p_schedule = np.ones(epochs)*inf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a standard training loop but with a detail that makes a big difference: you notice that I inflate the logits before PyTorch computes the softmax and the cross entropy loss.\n",
        "\n",
        "This is what is called the \"temperature\" of the softmax (see e.g. https://medium.com/@harshit158/softmax-temperature-5492e4007f71#:~:text=Temperature%20is%20a%20hyperparameter%20of%20LSTMs%20(and%20neural%20networks%20generally,utilize%20the%20Softmax%20decision%20layer.)\n",
        "\n",
        "We need to think about this and experiment, I'm not clear about why it improves things. But what is important is that it doesn't impact the prediction of the network (since scaling the logits doesn't change the order, so the \"winning class\" with the highest logit is still the same, but it impacts the training and seems to make it easier in our case). There may be non-desired effects however, for instance maybe logits will become too compressed and this will lead to low robustness, that's something we should look at later).\n",
        "\n",
        "The training is a bit unstable sometimes so run it several times!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6qmRQSNeJaS",
        "outputId": "464eaaf3-2b8b-4d96-d64a-09d36ef96c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0\tloss : 2.058633327484131, p: inf\n",
            "epoch 1\tloss : 1.7896616458892822, p: inf\n",
            "epoch 2\tloss : 1.4979101419448853, p: inf\n",
            "epoch 3\tloss : 2.810214042663574, p: inf\n",
            "epoch 4\tloss : 2.3779633045196533, p: inf\n",
            "epoch 5\tloss : 2.4536006450653076, p: inf\n",
            "epoch 6\tloss : 1.7067502737045288, p: inf\n",
            "epoch 7\tloss : 1.2071689367294312, p: inf\n",
            "epoch 8\tloss : 1.227992057800293, p: inf\n",
            "epoch 9\tloss : 1.4182642698287964, p: inf\n",
            "epoch 10\tloss : 1.0457887649536133, p: inf\n",
            "epoch 11\tloss : 0.8863292336463928, p: inf\n",
            "epoch 12\tloss : 0.927786111831665, p: inf\n",
            "epoch 13\tloss : 1.0944831371307373, p: inf\n",
            "epoch 14\tloss : 1.033191442489624, p: inf\n",
            "epoch 15\tloss : 0.8340880274772644, p: inf\n",
            "epoch 16\tloss : 0.8209742307662964, p: inf\n",
            "epoch 17\tloss : 0.9597315788269043, p: inf\n",
            "epoch 18\tloss : 0.9173004627227783, p: inf\n",
            "epoch 19\tloss : 0.8004856705665588, p: inf\n",
            "epoch 20\tloss : 0.8246299624443054, p: inf\n",
            "epoch 21\tloss : 0.8739787936210632, p: inf\n",
            "epoch 22\tloss : 0.8641759753227234, p: inf\n",
            "epoch 23\tloss : 0.814346432685852, p: inf\n",
            "epoch 24\tloss : 0.7769637703895569, p: inf\n",
            "epoch 25\tloss : 0.817244827747345, p: inf\n",
            "epoch 26\tloss : 0.837973952293396, p: inf\n",
            "epoch 27\tloss : 0.7790269255638123, p: inf\n",
            "epoch 28\tloss : 0.7714280486106873, p: inf\n",
            "epoch 29\tloss : 0.7945968508720398, p: inf\n",
            "epoch 30\tloss : 0.800951361656189, p: inf\n",
            "epoch 31\tloss : 0.7861746549606323, p: inf\n",
            "epoch 32\tloss : 0.7672711610794067, p: inf\n",
            "epoch 33\tloss : 0.7673965692520142, p: inf\n",
            "epoch 34\tloss : 0.777755856513977, p: inf\n",
            "epoch 35\tloss : 0.773601233959198, p: inf\n",
            "epoch 36\tloss : 0.7619783878326416, p: inf\n",
            "epoch 37\tloss : 0.7622559070587158, p: inf\n",
            "epoch 38\tloss : 0.7651662230491638, p: inf\n",
            "epoch 39\tloss : 0.7647254467010498, p: inf\n",
            "epoch 40\tloss : 0.7605175375938416, p: inf\n",
            "epoch 41\tloss : 0.7558315992355347, p: inf\n",
            "epoch 42\tloss : 0.7571168541908264, p: inf\n",
            "epoch 43\tloss : 0.7586544752120972, p: inf\n",
            "epoch 44\tloss : 0.7552359104156494, p: inf\n",
            "epoch 45\tloss : 0.7536781430244446, p: inf\n",
            "epoch 46\tloss : 0.7545993328094482, p: inf\n",
            "epoch 47\tloss : 0.7539268136024475, p: inf\n",
            "epoch 48\tloss : 0.7514724135398865, p: inf\n",
            "epoch 49\tloss : 0.751388669013977, p: inf\n",
            "epoch 50\tloss : 0.7534146904945374, p: inf\n",
            "epoch 51\tloss : 0.7500475645065308, p: inf\n",
            "epoch 52\tloss : 0.74836665391922, p: inf\n",
            "epoch 53\tloss : 0.7514260411262512, p: inf\n",
            "epoch 54\tloss : 0.7513607144355774, p: inf\n",
            "epoch 55\tloss : 0.747960090637207, p: inf\n",
            "epoch 56\tloss : 0.7476492524147034, p: inf\n",
            "epoch 57\tloss : 0.7505655884742737, p: inf\n",
            "epoch 58\tloss : 0.7488092184066772, p: inf\n",
            "epoch 59\tloss : 0.7465672492980957, p: inf\n",
            "epoch 60\tloss : 0.7485401630401611, p: inf\n",
            "epoch 61\tloss : 0.7490217089653015, p: inf\n",
            "epoch 62\tloss : 0.7470598816871643, p: inf\n",
            "epoch 63\tloss : 0.7469961643218994, p: inf\n",
            "epoch 64\tloss : 0.7482731342315674, p: inf\n",
            "epoch 65\tloss : 0.7472317218780518, p: inf\n",
            "epoch 66\tloss : 0.746624767780304, p: inf\n",
            "epoch 67\tloss : 0.7476001977920532, p: inf\n",
            "epoch 68\tloss : 0.7471389770507812, p: inf\n",
            "epoch 69\tloss : 0.7464646100997925, p: inf\n",
            "epoch 70\tloss : 0.7471141815185547, p: inf\n",
            "epoch 71\tloss : 0.7470917701721191, p: inf\n",
            "epoch 72\tloss : 0.746272623538971, p: inf\n",
            "epoch 73\tloss : 0.7467091083526611, p: inf\n",
            "epoch 74\tloss : 0.7470439672470093, p: inf\n",
            "epoch 75\tloss : 0.7463393211364746, p: inf\n",
            "epoch 76\tloss : 0.7463630437850952, p: inf\n",
            "epoch 77\tloss : 0.7468116283416748, p: inf\n",
            "epoch 78\tloss : 0.7464596033096313, p: inf\n",
            "epoch 79\tloss : 0.7462416291236877, p: inf\n",
            "epoch 80\tloss : 0.7465652227401733, p: inf\n",
            "epoch 81\tloss : 0.7464420199394226, p: inf\n",
            "epoch 82\tloss : 0.7462639808654785, p: inf\n",
            "epoch 83\tloss : 0.7464125156402588, p: inf\n",
            "epoch 84\tloss : 0.746370255947113, p: inf\n",
            "epoch 85\tloss : 0.7462552785873413, p: inf\n",
            "epoch 86\tloss : 0.7463453412055969, p: inf\n",
            "epoch 87\tloss : 0.7463151216506958, p: inf\n",
            "epoch 88\tloss : 0.7462300062179565, p: inf\n",
            "epoch 89\tloss : 0.7463022470474243, p: inf\n",
            "epoch 90\tloss : 0.7462818622589111, p: inf\n",
            "epoch 91\tloss : 0.7462121248245239, p: inf\n",
            "epoch 92\tloss : 0.7462553381919861, p: inf\n",
            "epoch 93\tloss : 0.7462660074234009, p: inf\n",
            "epoch 94\tloss : 0.746203601360321, p: inf\n",
            "epoch 95\tloss : 0.7462199330329895, p: inf\n",
            "epoch 96\tloss : 0.7462419867515564, p: inf\n",
            "epoch 97\tloss : 0.7462090253829956, p: inf\n",
            "epoch 98\tloss : 0.7461961507797241, p: inf\n",
            "epoch 99\tloss : 0.7462180256843567, p: inf\n",
            "CPU times: user 1min 41s, sys: 1.16 s, total: 1min 42s\n",
            "Wall time: 20.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "  for j,(x_t,y_t) in enumerate(trainloader):\n",
        "\n",
        "    #calculate output\n",
        "    output = model(x_t.float().to(device), p_schedule[i])\n",
        "    output2 = output*100\n",
        "\n",
        "\n",
        "    y_t = y_t.long()\n",
        "    #calculate loss\n",
        "    loss = loss_fn(output2, y_t)\n",
        "\n",
        "    #backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i%1 == 0:\n",
        "    losses.append(loss)\n",
        "    print(\"epoch {}\\tloss : {}, p: {}\".format(i,loss, p_schedule[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TME1saCEeJaS"
      },
      "outputs": [],
      "source": [
        "test_loss, correct, preds, ground_truth = test(testloader, model, loss_fn, p=inf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6EkPi9neJaS",
        "outputId": "6c5237d8-f935-4f09-9a20-867cfa776413"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.71"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Pw429QUqi1NZ",
        "outputId": "21260950-37bb-4756-f89e-f8a5e9a7e6db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cfm = confusion_matrix(ground_truth[0].cpu().numpy(), preds[0].cpu().numpy())\n",
        "sns.heatmap(cfm, annot=True, fmt='g')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Checking the output\n",
        "\n",
        "Below I have some code to check the margin (difference between the logits for the \"winning class\" and the next biggest one), as this is what is used to compute the robustness (see the \"Towards Certifying l Robustness using Neural Networks with l-dist Neurons\" paper). This should be changed to only look at it for samples that are correctly classified, and also looking separately at train and test set to see if there is any difference).\n",
        "\n",
        "We then need to relate this back to the Wasserstein/bottleneck distances and try to understand what it means there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ycgc2ScKeJaT"
      },
      "outputs": [],
      "source": [
        "output = model(matrixSTens.float().to(device), p=inf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iP8_8yqj-iY",
        "outputId": "63c96778-8a1a-4850-c5dc-ae493c897895"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3254, 0.3304, 0.3278, 0.2967, 0.3011],\n",
              "        [0.3505, 0.3011, 0.3282, 0.2673, 0.3263],\n",
              "        [0.3255, 0.3328, 0.3242, 0.2991, 0.3001],\n",
              "        ...,\n",
              "        [0.3207, 0.2346, 0.3187, 0.3016, 0.3503],\n",
              "        [0.3300, 0.2405, 0.3300, 0.2914, 0.3438],\n",
              "        [0.3237, 0.2216, 0.3224, 0.3201, 0.3636]], grad_fn=<CdistBackward0>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "U_zEzZRjjZjN"
      },
      "outputs": [],
      "source": [
        "output_sorted = torch.sort(output, dim=1, descending=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lyqoTDCQkkEb"
      },
      "outputs": [],
      "source": [
        "output_diff = output_sorted[:,0] - output_sorted[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5itJ_B6kqB8",
        "outputId": "9d5e6a94-78e9-43a8-9786-3d0d4ebb6fa4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.0196, grad_fn=<MeanBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(output_diff).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next I compute the distances between all samples:\n",
        "- Between stable ranks\n",
        "- Between the representation learned by the neural network (output logits, 5 dimensional)\n",
        "\n",
        "This will be very important to look closely at:\n",
        "- Distance between the NN representations should never be larger than the distance between stable ranks because we are using the Lipschitz layer, but we should verify this!\n",
        "- How much does it \"compress\" things, for instance at a first look the distance between the representations seems to be equal to the distance between stable ranks for many samples. What is going on there, how can that be the case?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6Y-vVl9HexkU"
      },
      "outputs": [],
      "source": [
        "distMatStab = torch.cdist(matrixSTens, matrixSTens, p=inf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VaiUghvae-yz"
      },
      "outputs": [],
      "source": [
        "distMatRep = torch.cdist(output, output, p=inf).to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8p4Rq0Z4fQOh"
      },
      "outputs": [],
      "source": [
        "factors = distMatRep / distMatStab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8P09G-0BfkEC"
      },
      "outputs": [],
      "source": [
        "factors[torch.isnan(factors)] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.9564, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "factors.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoEcLwRqftMz",
        "outputId": "06e3d474-f6d6-4733-c22b-1c05beec6086"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.0004, dtype=torch.float64, grad_fn=<MaxBackward1>)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "factors.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "klTtz0rSgCFo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 1.0000, 0.7627,  ..., 0.9575, 1.0000, 0.9187],\n",
              "        [1.0000, 0.0000, 1.0000,  ..., 0.9399, 1.0000, 0.8919],\n",
              "        [0.7627, 1.0000, 0.0000,  ..., 0.9585, 1.0000, 0.9203],\n",
              "        ...,\n",
              "        [0.9575, 0.9399, 0.9585,  ..., 0.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
              "        [0.9187, 0.8919, 0.9203,  ..., 1.0000, 1.0000, 0.0000]],\n",
              "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "factors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
